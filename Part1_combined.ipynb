{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_combined.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eun0sMvJ90GZ",
        "jFSJ3fe0EC-R",
        "d98u6TeSGgvn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tBGqfXE-o3y"
      },
      "source": [
        "## Set up\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XYibaPl9TXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deaf7e08-2387-42c6-8efe-913d75f841be"
      },
      "source": [
        "# Imports\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download(\"punkt\")\r\n",
        "\r\n",
        "# !pip install gensim\r\n",
        "import gensim\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from torch.utils.data import Dataset, random_split\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "import codecs\r\n",
        "import os\r\n",
        "\r\n",
        "import tensorboard as tb\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "import random\r\n",
        "\r\n",
        "writer = SummaryWriter('runs/word2vec')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZifcs_HULHo",
        "outputId": "d4a69992-23f9-4d88-85a8-f0966bd5cb48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCmuKUmXD7rK"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "# !unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V38uzVSk9lbi"
      },
      "source": [
        "# Setting random seed and device\r\n",
        "SEED = 1\r\n",
        "\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "# mount drive\r\n",
        "if not os.path.exists('/content/drive/MyDrive/ICL AI/NLP/NLP_cw'):\r\n",
        "    print(\"making dir\")\r\n",
        "    os.makedirs('/content/drive/MyDrive/ICL AI/NLP/NLP_cw')\r\n",
        "\r\n",
        "root_path = '/content/drive/MyDrive/ICL AI/NLP/NLP_cw/'\r\n",
        "\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FMny8--sCS"
      },
      "source": [
        "## Hyperparameters and data loading\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uONHCtoV-vuZ"
      },
      "source": [
        "# Load data for training purposes\r\n",
        "# Data is stored locally in my drive at [root]/data/task-1\r\n",
        "train_df = pd.read_csv(f'{root_path}train.csv')\r\n",
        "dev_df = pd.read_csv(f'{root_path}dev.csv')\r\n",
        "test_df = pd.read_csv(f'{root_path}test.csv')\r\n",
        "\r\n",
        "# make sure data is in same folder as root dir!\r\n",
        "# train_df = pd.read_csv('train.csv')\r\n",
        "# dev_df = pd.read_csv('dev.csv')\r\n",
        "# test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k53yu8r19o6S"
      },
      "source": [
        "# Number of epochs\r\n",
        "epochs = 10\r\n",
        "\r\n",
        "# Proportion of training data for train compared to dev\r\n",
        "train_proportion = 0.8\r\n",
        "\r\n",
        "# which batch size?\r\n",
        "BATCH_SIZE = 32  # hyperparam"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuGH1nhICbS"
      },
      "source": [
        "# which model?\r\n",
        "# affects:\r\n",
        "# - train/evaluation, as BiLSTM has an extra hidden layer initialisation step\r\n",
        "# - creation of features, as BiLSTM features are padded within batches and FFN\r\n",
        "#   features are padded within the entire dataset\r\n",
        "\r\n",
        "options_models = [\"BiLSTM\", \"BiLSTM-Attention\", \"FFN\"]\r\n",
        "\r\n",
        "model_to_run = 2  # 0 = BiLSTM, 1 = BiLSTM-Attention, 2 = FFN\r\n",
        "\r\n",
        "# which embedding?\r\n",
        "# affects:\r\n",
        "# - which embeddings file is loaded and used to make word2id, idx2word & wvecs\r\n",
        "# - which tokenizer is used, as GloVe doesn't play nice with the ntkl tokenizer\r\n",
        "\r\n",
        "options = [f'{root_path}glove.6B.100d.txt', 'custom_word2vec.txt', \"custom_fasttext.txt\"]\r\n",
        "\r\n",
        "picked_embeddings = 2  # 0 = pre-made glove, 1 = custom word2vec, 2 = custom fasttext\r\n",
        "\r\n",
        "# file to load the embeddings from\r\n",
        "# embedding files should be txt and located in the same working dir as the .ipynb\r\n",
        "file_to_load = options[picked_embeddings]  "
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eun0sMvJ90GZ"
      },
      "source": [
        "## Preprocessing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypvEawWUBhnu"
      },
      "source": [
        "### Making vocabulary\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLXdY2DBBazo"
      },
      "source": [
        "def create_vocab(data):\r\n",
        "    \"\"\"\r\n",
        "    Creating a corpus of all the tokens used\r\n",
        "    \"\"\"\r\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\r\n",
        "    punctuation_exclusion = [\",\", \"\\'\", \"\\\"\", \".\", \"‘\", \"’\"] \r\n",
        "\r\n",
        "    for sentence in data:\r\n",
        "\r\n",
        "        if picked_embeddings == 0: # glove embeddings\r\n",
        "\r\n",
        "          tokenized_sentence = []\r\n",
        "          for token in sentence.split(' '): # simplest split is\r\n",
        "            tokenized_sentence.append(token)\r\n",
        "\r\n",
        "            # tokenized_corpus.append(tokenized_sentence)\r\n",
        "        else:\r\n",
        "          # using nltk tokenizer        \r\n",
        "          tokenized_sentence = nltk.tokenize.word_tokenize(sentence.lower())\r\n",
        "\r\n",
        "        cleaned = [token for token in tokenized_sentence if token not in punctuation_exclusion]\r\n",
        "        tokenized_corpus.append(cleaned)\r\n",
        "\r\n",
        "    # Create single list of all vocabulary\r\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\r\n",
        "\r\n",
        "    for sentence in tokenized_corpus:\r\n",
        "\r\n",
        "        for token in sentence:\r\n",
        "\r\n",
        "            if token not in vocabulary:\r\n",
        "\r\n",
        "                if True:\r\n",
        "                    vocabulary.append(token)\r\n",
        "\r\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grvrWYyxBk3o"
      },
      "source": [
        "### Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfyNRwh3Bd-g"
      },
      "source": [
        "def collate_fn_padd(batch):\r\n",
        "    '''\r\n",
        "    We add padding to our minibatches and create tensors for our model\r\n",
        "    '''\r\n",
        "\r\n",
        "    batch_labels = [l for f, l in batch]\r\n",
        "    batch_features = [f for f, l in batch]\r\n",
        "\r\n",
        "    batch_features_len = [len(f) for f, l in batch]\r\n",
        "\r\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\r\n",
        "\r\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\r\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\r\n",
        "\r\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\r\n",
        "\r\n",
        "    return seq_tensor, batch_labels\r\n",
        "\r\n",
        "class Task1Dataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, train_data, labels):\r\n",
        "        self.x_train = train_data\r\n",
        "        self.y_train = labels\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.y_train)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0RrQJm-BuIZ"
      },
      "source": [
        "## Model\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9KyF1nDm8I"
      },
      "source": [
        "### BiLSTM\r\n",
        "\r\n",
        "copied from spec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPupmNK0DqAy"
      },
      "source": [
        "class BiLSTM(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\r\n",
        "        super(BiLSTM, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.device = device\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\r\n",
        "\r\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\r\n",
        "        # with dimensionality hidden_dim.\r\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\r\n",
        "\r\n",
        "        # The linear layer that maps from hidden state space to tag space\r\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        # Before we've done anything, we dont have any hidden state.\r\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\r\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "    def forward(self, sentence):\r\n",
        "        embedded = self.embedding(sentence)\r\n",
        "        embedded = embedded.permute(1, 0, 2)\r\n",
        "\r\n",
        "        lstm_out, self.hidden = self.lstm(\r\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\r\n",
        "\r\n",
        "        out = self.hidden2label(lstm_out[-1])\r\n",
        "        return out"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxNyjbbyDtIo"
      },
      "source": [
        "### Custom NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsPapUCRFigV"
      },
      "source": [
        "#### BiLSTM Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlMHTIAFmkB"
      },
      "source": [
        "class BiLSTM_ATT(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM_ATT, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        # Attention layers\n",
        "        self.attention_linear = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim * 2, bias = True),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.attention_softmax = nn.Softmax(dim = 0)\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedded = self.embedding(sentence)\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "        \n",
        "        # Attention Layers\n",
        "        att_in = lstm_out\n",
        "        # Linear operation\n",
        "        att_linear = self.attention_linear(att_in[-1])\n",
        "        \n",
        "        # Apply softmax to get weight of h_ti, t being the num of length of embedded, i being our embedding dim\n",
        "        att_softmax = self.attention_softmax(att_linear)\n",
        "\n",
        "        # Extract feature vector\n",
        "        # Here we extract SUM_(j=1)^t w_i * h_i\n",
        "        feature_vector = torch.sum(att_softmax * att_in, dim=0)\n",
        "        # Feature vector now has size batch size * embedding dim\n",
        "\n",
        "        out = self.hidden2label(feature_vector)\n",
        "        return out"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbIwULGWvcYZ"
      },
      "source": [
        "#### Pytorch dense NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRtNSpGeCb3v"
      },
      "source": [
        "Also attempted a GRU, but it didn't work, so stuck with feed-forward NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0pvde-wu5Ui"
      },
      "source": [
        "class FFN(nn.Module):\r\n",
        "    def __init__(self, embedding_dim, vocab_size, batch_size, max_feature):\r\n",
        "        super(FFN, self).__init__()\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(embedding_dim*max_feature, 128),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(128, 64),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(64, 32),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(32, 1),\r\n",
        "            nn.Tanh()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      # input shape: [batch size, sentence length]\r\n",
        "      input_len = x.size()[1]\r\n",
        "\r\n",
        "      # print(\"input size:\", x.size()) \r\n",
        "      # print(\"input: \", x)\r\n",
        "\r\n",
        "      # embedding output shape: [batch size, sentence length, embedding dim]\r\n",
        "      embedded = self.embedding(x).view((self.batch_size, -1))\r\n",
        "\r\n",
        "      out = self.model(embedded)\r\n",
        "      return out"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZggpD3BMZA"
      },
      "source": [
        "## Train & eval\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Av0OzfBOJx"
      },
      "source": [
        "# We define our training loop\r\n",
        "def train(train_iter, dev_iter, model, number_epoch):\r\n",
        "    \"\"\"\r\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    \r\n",
        "    print(\"Training model.\")\r\n",
        "    print(type(model).__name__)\r\n",
        "\r\n",
        "    train_loss = []\r\n",
        "    valid_loss_l = []\r\n",
        "    train_mse = []\r\n",
        "    valid_mse_l = []\r\n",
        "    train_rmse = []\r\n",
        "    valid_rmse_l = []\r\n",
        "\r\n",
        "    for epoch in range(1, number_epoch+1):\r\n",
        "\r\n",
        "        model.train()\r\n",
        "        epoch_loss = 0\r\n",
        "        epoch_sse = 0\r\n",
        "        no_observations = 0  # Observations used for training so far\r\n",
        "\r\n",
        "        for batch in train_iter:\r\n",
        "\r\n",
        "            feature, target = batch\r\n",
        "\r\n",
        "            feature, target = feature.to(device), target.to(device)\r\n",
        "\r\n",
        "            # for RNN:\r\n",
        "            model.batch_size = target.shape[0]\r\n",
        "            no_observations = no_observations + target.shape[0]\r\n",
        "\r\n",
        "            # initalise hidden layers for BiLSTM (& BiLSTM w/ attention) only\r\n",
        "            if model_to_run == 0 or model_to_run == 1:  \r\n",
        "              model.hidden = model.init_hidden()\r\n",
        "\r\n",
        "            predictions = model(feature).squeeze(1)\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            loss = loss_fn(predictions, target)\r\n",
        "\r\n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            epoch_loss += loss.item()*target.shape[0]\r\n",
        "            epoch_sse += sse\r\n",
        "\r\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\r\n",
        "\r\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\r\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\r\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\r\n",
        "\r\n",
        "        train_loss.append(epoch_loss)\r\n",
        "        valid_loss_l.append(valid_loss)\r\n",
        "        train_mse.append(epoch_mse)\r\n",
        "        valid_mse_l.append(valid_mse)\r\n",
        "        train_rmse.append(epoch_mse**.5)\r\n",
        "        valid_rmse_l.append(valid_mse**.5)\r\n",
        "    return train_loss, train_mse, train_rmse, valid_loss_l, valid_mse_l, valid_rmse_l"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vf1n-U_BRgc"
      },
      "source": [
        "\r\n",
        "# We evaluate performance on our dev set\r\n",
        "def eval(data_iter, model):\r\n",
        "    \"\"\"\r\n",
        "    Evaluating model performance on the dev set\r\n",
        "    \"\"\"\r\n",
        "    model.eval()\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_sse = 0\r\n",
        "    pred_all = []\r\n",
        "    trg_all = []\r\n",
        "    no_observations = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for batch in data_iter:\r\n",
        "            feature, target = batch\r\n",
        "\r\n",
        "            feature, target = feature.to(device), target.to(device)\r\n",
        "\r\n",
        "            # for RNN:\r\n",
        "            model.batch_size = target.shape[0]\r\n",
        "            no_observations = no_observations + target.shape[0]\r\n",
        "            if model_to_run == 0 or model_to_run == 1:\r\n",
        "              model.hidden = model.init_hidden()\r\n",
        "\r\n",
        "            predictions = model(feature).squeeze(1)\r\n",
        "            loss = loss_fn(predictions, target)\r\n",
        "\r\n",
        "            # We get the mse\r\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\r\n",
        "            sse, __ = model_performance(pred, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()*target.shape[0]\r\n",
        "            epoch_sse += sse\r\n",
        "            pred_all.extend(pred)\r\n",
        "            trg_all.extend(trg)\r\n",
        "\r\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t3UqMhwBWAg"
      },
      "source": [
        "# How we print the model performance\r\n",
        "def model_performance(output, target, print_output=False):\r\n",
        "    \"\"\"\r\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    sq_error = (output - target)**2\r\n",
        "\r\n",
        "    sse = np.sum(sq_error)\r\n",
        "    mse = np.mean(sq_error)\r\n",
        "    rmse = np.sqrt(mse)\r\n",
        "\r\n",
        "    if print_output:\r\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\r\n",
        "\r\n",
        "    return sse, mse"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EZEjWv-B_MP"
      },
      "source": [
        "## Configure data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20DTU-htGi5A"
      },
      "source": [
        "#### Edit original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ScGrt6GqQa"
      },
      "source": [
        "# Edit original sentences\n",
        "# replace word in original sentence with edit substitution\n",
        "\n",
        "import re\n",
        "\n",
        "# train\n",
        "original_training_data = train_df['original']\n",
        "train_edit = train_df['edit']\n",
        "train_edited = [re.sub('<(.+)/>', '<' + edit +'/>', data) for data, edit in zip(original_training_data, train_edit)]\n",
        "\n",
        "# dev\n",
        "original_dev_data = dev_df['original']\n",
        "dev_edit = dev_df['edit']\n",
        "dev_edited = [re.sub('<(.+)/>', '<' + edit + '/>', data) for data, edit in zip(original_dev_data, dev_edit)]\n",
        "\n",
        "# test\n",
        "original_test_data = test_df['original']\n",
        "test_edit = test_df['edit']\n",
        "test_edited = [re.sub('<(.+)/>', '<' + edit + '/>', data) for data, edit in zip(original_test_data, test_edit)]\n",
        "\n",
        "\n",
        "train_df['full_edited'] = train_edited\n",
        "dev_df['full_edited'] = dev_edited\n",
        "test_df['full_edit'] = test_edited"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGdNKissCcoo"
      },
      "source": [
        "#### Setting data, creating vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlZ-1aHeCgNA",
        "outputId": "d82dfeaa-299c-466d-df50-f2e93d388cf7"
      },
      "source": [
        "# We set our training data and dev data\r\n",
        "training_data = train_df['full_edited']\r\n",
        "dev_data = dev_df['full_edited']\r\n",
        "\r\n",
        "# Creating word vectors from train data\r\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\r\n",
        "\r\n",
        "# Creating word vectors from dev data\r\n",
        "dev_vocab, dev_tokenized_corpus = create_vocab(dev_data)\r\n",
        "\r\n",
        "# vector for test data\r\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\r\n",
        "print(\"Test vocab created.\")\r\n",
        "\r\n",
        "# Creating joint vocab from dev and train:\r\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, dev_data]))\r\n",
        "print(\"Train & development vocab created.\")"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test vocab created.\n",
            "Train & development vocab created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28wxpSBlbPii",
        "outputId": "db65aad8-da66-40f1-9039-b0e330905168"
      },
      "source": [
        "print(joint_tokenized_corpus[:10])"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['france', 'is', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', '<', 'twins/', '>', 'without', 'trial', 'in', 'iraq'], ['pentagon', 'claims', '2,000', '%', 'increase', 'in', 'russian', 'trolls', 'after', '<', 'bowling/', '>', 'strikes', 'what', 'does', 'that', 'mean', '?'], ['iceland', 'pm', 'calls', 'snap', 'vote', 'as', 'pedophile', 'furor', 'crashes', '<', 'party/', '>'], ['in', 'an', 'apparent', 'first', 'iran', 'and', 'israel', '<', 'slap/', '>', 'each', 'other', 'militarily'], ['trump', 'was', 'told', 'weeks', 'ago', 'that', 'flynn', 'misled', '<', 'school/', '>', 'president'], ['all', '22', '<', 'sounds/', '>', 'trump', 'made', 'in', 'his', 'speech', 'to', 'congress', 'in', 'one', 'chart'], ['new', 'doj', 'alert', 'system', 'will', 'flag', '<', 'laughter/', '>', 'against', 'police'], ['as', 'someone', 'who', 'grew', 'up', 'among', 'fundamentalist', '<', 'morons/', '>', 'in', 'the', 'us', 'i', \"'m\", 'surprised', 'anyone', \"'s\", 'surprised', 'about', 'roy', 'moore'], ['canadians', 'may', 'pay', 'more', 'taxes', 'than', 'americans', 'but', 'here', \"'s\", 'what', 'they', 'get', 'for', 'their', '<', 'loonies/', '>'], ['dutch', 'minister', 'resigns', 'in', 'drug', 'baron', '<', 'blow/', '>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iq40AKwCnNI"
      },
      "source": [
        "## Creating embeddings\r\n",
        "Pre-trained embeddings (GloVE) should be saved in the same folder as the embeddings created here. This is usually the working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOWJPASFVagz"
      },
      "source": [
        "##### word2vec with gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfPh1wKvVdfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193c5644-0648-4f64-b491-9b445d001237"
      },
      "source": [
        "if picked_embeddings == 1:\r\n",
        "  # word2vec\r\n",
        "  model1 = gensim.models.Word2Vec(joint_tokenized_corpus, min_count = 1,  \r\n",
        "                                size = 100, window = 5, sg = 1)\r\n",
        "\r\n",
        "  model1.wv.save_word2vec_format(\"custom_word2vec.txt\")\r\n",
        "else:\r\n",
        "  print(f\"picked {options[picked_embeddings]} embeddings, so not creating custom word2vec embeddings\")"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picked custom_fasttext.txt embeddings, so not creating custom word2vec embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8ZKQnJ029v"
      },
      "source": [
        "##### fasttext with gensim\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZOdY01ydve"
      },
      "source": [
        "# fasttext\r\n",
        "# fastText — which is essentially an extension of the word2vec model — \r\n",
        "# treats each *word* as composed of character n-grams. \r\n",
        "\r\n",
        "if picked_embeddings == 2: # fasttext\r\n",
        "  model2 = gensim.models.FastText(joint_tokenized_corpus, min_count = 1,\r\n",
        "                                  size=100, window = 5, sg = 1)\r\n",
        "\r\n",
        "  model2.wv.save_word2vec_format(\"custom_fasttext.txt\")\r\n",
        "else:\r\n",
        "  print(f\"picked {options[picked_embeddings]} embeddings, so not creating custom fasttext embeddings\")"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiqHkiHuxTL_"
      },
      "source": [
        "#### Set embeddings from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Y5_3RHtAen"
      },
      "source": [
        "# We create representations for our tokens\r\n",
        "\r\n",
        "# opens correct embeddings file set in previous cell\r\n",
        "def create_wvecs(embed_file, vocab, tokenized_corpus):\r\n",
        "  \"\"\"\r\n",
        "  Takes in whatever vocab & corpus\r\n",
        "  embed_file should be .txt file containing embeddings\r\n",
        "  \"\"\"\r\n",
        "  wvecs = [] # word vectors\r\n",
        "  word2idx = [] # word2index\r\n",
        "  idx2word = []\r\n",
        "\r\n",
        "  # This is a large file, it will take a while to load in the memory!\r\n",
        "  with codecs.open(embed_file, 'r','utf-8') as f:\r\n",
        "    index = 1\r\n",
        "    for line in f.readlines():\r\n",
        "      # Ignore the first line - first line typically contains vocab, dimensionality\r\n",
        "      if len(line.strip().split()) > 3:\r\n",
        "        word = line.strip().split()[0]\r\n",
        "        if word in vocab:\r\n",
        "            (word, vec) = (word,\r\n",
        "                      list(map(float,line.strip().split()[1:])))\r\n",
        "            wvecs.append(vec)\r\n",
        "            word2idx.append((word, index))\r\n",
        "            idx2word.append((index, word))\r\n",
        "            index += 1\r\n",
        "\r\n",
        "  wvecs = np.array(wvecs)\r\n",
        "  word2idx = dict(word2idx)\r\n",
        "  idx2word = dict(idx2word)\r\n",
        "\r\n",
        "  vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in tokenized_corpus]\r\n",
        "\r\n",
        "  # To avoid any sentences being empty (if no words match to our word embeddings)\r\n",
        "  vectorized_seqs = [x if len(x) > 0 else [0] for x in vectorized_seqs]\r\n",
        "\r\n",
        "  return wvecs, word2idx, idx2word, vectorized_seqs\r\n"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXcouB6p7bHa"
      },
      "source": [
        "## Creating batches and model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp5U4D9EDErI"
      },
      "source": [
        "#### Splitting dataset & padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhkAqxzTLI0J"
      },
      "source": [
        "# padd entire dataset to the longest sentence\r\n",
        "# used for the FFN\r\n",
        "# not necessary for the LSTM\r\n",
        "\r\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\r\n",
        "wvecs, word2idx, idx2word, vectorized_seqs = create_wvecs(file_to_load, \r\n",
        "                                                          joint_vocab, \r\n",
        "                                                          training_tokenized_corpus)\r\n",
        "\r\n",
        "\r\n",
        "test_wvecs, _, _, vectorized_seqs_test = create_wvecs(file_to_load, \r\n",
        "                                                      test_vocab, \r\n",
        "                                                      test_tokenized_corpus)\r\n",
        "\r\n",
        "# manual padding to longest sentence\r\n",
        "def find_max_list(list_in):\r\n",
        "    list_len = [len(i) for i in list_in]\r\n",
        "    return max(list_len)\r\n",
        "\r\n",
        "def padd_full_data(input_feature, max_len):\r\n",
        "  padd_feature = []\r\n",
        "  for sentence in input_feature:\r\n",
        "    if len(sentence) < max_len:\r\n",
        "\r\n",
        "      diff = max_len - len(sentence)\r\n",
        "      new_list = [0]*diff\r\n",
        "      sentence.extend(new_list)\r\n",
        "\r\n",
        "      assert len(sentence) == max_len\r\n",
        "\r\n",
        "    padd_feature.append(sentence)\r\n",
        "\r\n",
        "  return padd_feature\r\n",
        "\r\n",
        "if model_to_run == 0 or model_to_run == 1:  # BiLSTM or BiLSTM Attention\r\n",
        "  feature = vectorized_seqs\r\n",
        "  max_len = 90348 # placeholder \r\n",
        "elif model_to_run == 2:  # FFN, all batches need to have same length\r\n",
        "\r\n",
        "  # check whether theres a sequence in the test set thats longer than in train\r\n",
        "  max_len_train = find_max_list(vectorized_seqs)\r\n",
        "  max_len_test = find_max_list(vectorized_seqs_test)\r\n",
        "\r\n",
        "  if max_len_train > max_len_test:\r\n",
        "    max_len = max_len_train\r\n",
        "  else:\r\n",
        "    max_len = max_len_test\r\n",
        "\r\n",
        "  # pad training sequences to max length in entire dataset\r\n",
        "  feature = padd_full_data(vectorized_seqs, max_len)\r\n",
        "\r\n",
        "  # pad test sequences to max length in entire dataset\r\n",
        "  feature_test = padd_full_data(vectorized_seqs_test, max_len)\r\n",
        "    "
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS1JwXi5C71_"
      },
      "source": [
        "#### Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oARCFR5CDBIm",
        "outputId": "cdc46386-7038-4c1d-836c-2228c8348291"
      },
      "source": [
        "INPUT_DIM = len(word2idx)  # numbers of tokens\r\n",
        "EMBEDDING_DIM = 100  # hyperparam\r\n",
        "MAX_LEN = max_len\r\n",
        "\r\n",
        "if model_to_run == 2:  # FFN, max len is length all sentences are padded to\r\n",
        "  model = FFN(EMBEDDING_DIM, INPUT_DIM, BATCH_SIZE, MAX_LEN)\r\n",
        "elif model_to_run == 0: # BiLSTM, 50 is hidden state size\r\n",
        "  model = BiLSTM(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\r\n",
        "elif model_to_run == 1: # BiLSTM Attention, 50 is hidden state size\r\n",
        "  model = BiLSTM_ATT(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "model.to(device)\r\n",
        "# We provide the model with our embeddings\r\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0189, -0.1200, -0.2173,  ..., -0.1493, -0.2551,  0.1526],\n",
              "        [-0.1644,  0.0287, -0.1004,  ..., -0.0480, -0.3070,  0.2768],\n",
              "        [ 0.1596, -0.0489, -0.4639,  ...,  0.2395, -0.6067, -0.1490],\n",
              "        ...,\n",
              "        [-0.0996,  0.0444, -0.6507,  ..., -0.0224, -0.6407,  0.3695],\n",
              "        [-0.1289,  0.0533, -0.5917,  ...,  0.0033, -0.5867,  0.2856],\n",
              "        [-0.0463,  0.0692, -0.6014,  ..., -0.0291, -0.5963,  0.3522]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95pmtD63Yq-e"
      },
      "source": [
        "### Creating train & dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhvywH_XDHfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e278cb-6a91-4dfe-e824-ff6e3cf69e37"
      },
      "source": [
        "\r\n",
        "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\r\n",
        "\r\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\r\n",
        "dev_examples = len(train_and_dev) - train_examples\r\n",
        "\r\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\r\n",
        "                                           (train_examples,\r\n",
        "                                            dev_examples))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "\r\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrL21L4V7dVS"
      },
      "source": [
        "## Running model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM69uHwxDILw"
      },
      "source": [
        "#### Running model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfpiPnn792fZ",
        "outputId": "22997b6f-d77d-4d12-8417-b0322fcf3c27"
      },
      "source": [
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "print(f\"running model {options_models[model_to_run]} with embeddings {file_to_load}\")\r\n",
        "\r\n",
        "# for making graphs\r\n",
        "train_l, train_mse, train_rmse, valid_l, valid_mse, valid_rmse = train(train_loader,dev_loader, model,epochs)\r\n",
        "\r\n",
        "# on BiLSTM w/o padding:\r\n",
        "# custom word2vec embed: \r\n",
        "# | Epoch: 10 | Train Loss: 0.13 | Train MSE: 0.13 | Train RMSE: 0.35 | Val. Loss: 0.44 | Val. MSE: 0.44 |  Val. RMSE: 0.66 |\r\n",
        "\r\n",
        "# glove embed:\r\n",
        "# | Epoch: 10 | Train Loss: 0.22 | Train MSE: 0.22 | Train RMSE: 0.47 | Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\r\n",
        "\r\n",
        "# custom fasttext embed:\r\n",
        "# | Epoch: 10 | Train Loss: 0.12 | Train MSE: 0.12 | Train RMSE: 0.35 | Val. Loss: 0.46 | Val. MSE: 0.46 |  Val. RMSE: 0.67 |\r\n",
        "\r\n",
        "\r\n",
        "# on FFN w/ padding to len 26:\r\n",
        "# custom word2vec: \r\n",
        "# | Epoch: 10 | Train Loss: 0.11 | Train MSE: 0.11 | Train RMSE: 0.33 |         Val. Loss: 0.45 | Val. MSE: 0.45 |  Val. RMSE: 0.67 |\r\n",
        "\r\n",
        "# custom fasttext:\r\n",
        "# | Epoch: 10 | Train Loss: 0.11 | Train MSE: 0.11 | Train RMSE: 0.33 |         Val. Loss: 0.43 | Val. MSE: 0.43 |  Val. RMSE: 0.65 |\r\n",
        "\r\n",
        "# pre trained glove:\r\n",
        "# | Epoch: 10 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 "
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running model FFN with embeddings custom_fasttext.txt\n",
            "Training model.\n",
            "FFN\n",
            "| Epoch: 01 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 02 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 03 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 04 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
            "| Epoch: 05 | Train Loss: 0.22 | Train MSE: 0.22 | Train RMSE: 0.47 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 06 | Train Loss: 0.21 | Train MSE: 0.21 | Train RMSE: 0.45 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 07 | Train Loss: 0.19 | Train MSE: 0.19 | Train RMSE: 0.44 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 08 | Train Loss: 0.19 | Train MSE: 0.19 | Train RMSE: 0.44 |         Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 09 | Train Loss: 0.19 | Train MSE: 0.19 | Train RMSE: 0.43 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 10 | Train Loss: 0.18 | Train MSE: 0.18 | Train RMSE: 0.42 |         Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIwn7Wg3HTlY"
      },
      "source": [
        "#### Running model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5X2w0-zHl_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eed3de0-8bcc-4616-b0ff-1bc1707e1517"
      },
      "source": [
        "def model_test(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the test set\n",
        "    \"\"\"\n",
        "    test_loss, test_mse, _, _ = eval(data_iter, model)\n",
        "\n",
        "    print(f'| Test Loss: {test_loss:.2f} | Test MSE: {test_mse:.2f} |  Test RMSE: {test_mse**0.5:.2f} |')\n",
        "\n",
        "test_data = test_df['full_edit']\n",
        "\n",
        "# test vocab, test_wvecs & vectorized_seqs_test are already initialised above\n",
        "\n",
        "# We provide the model with our embeddings\n",
        "if model_to_run == 0 or model_to_run == 1:  # BiLSTM or BiLSTM with attention\n",
        "  feature_test = vectorized_seqs_test\n",
        "elif model_to_run == 2: # FFN\n",
        "  feature_test = feature_test  # already set earlier\n",
        "\n",
        "test_dataset = Task1Dataset(feature_test, test_df['meanGrade'])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "print(f\"Testing on {options_models[model_to_run]} with embeddings {file_to_load}\")\n",
        "model_test(test_loader, model)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n",
            "Testing on FFN with embeddings custom_fasttext.txt\n",
            "| Test Loss: 0.39 | Test MSE: 0.39 |  Test RMSE: 0.62 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxfEKTjbv84T"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3sZskBf7v-_j",
        "outputId": "f9fa0d52-4730-48b0-c332-68f2179c1aac"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.style.use(\"bmh\")\r\n",
        "plt.plot(np.arange(0, len(train_l)), train_l, label=\"train loss\")\r\n",
        "plt.plot(np.arange(0, len(valid_l)), valid_l, label=\"validation loss\")\r\n",
        "\r\n",
        "# plt.plot(np.arange(0, len(train_rsme)), train_rsme, label=\"train RMSE\")\r\n",
        "# plt.plot(np.arange(0, len(valid_rsme)), valid_rsme, label=\"validation RMSE\")\r\n",
        "plt.legend(loc=\"best\")\r\n",
        "\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.xlabel(\"epochs\")\r\n",
        "\r\n",
        "plt.title(f\"Train and validation loss over the epochs for {options_models[model_to_run]} model\\n\"\r\n",
        "          \"Trained on custom word2vec embeddings\")\r\n",
        "\r\n",
        "plt.show()\r\n",
        "# print(train_losses_D)\r\n",
        "# print(train_losses_G)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}