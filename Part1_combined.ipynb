{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_combined.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eun0sMvJ90GZ",
        "jFSJ3fe0EC-R",
        "d98u6TeSGgvn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tBGqfXE-o3y"
      },
      "source": [
        "## Set up\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XYibaPl9TXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ca96ad-591d-4859-9f59-3a0bc0c754bd"
      },
      "source": [
        "# Imports\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download(\"punkt\")\r\n",
        "\r\n",
        "# !pip install gensim\r\n",
        "import gensim\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from torch.utils.data import Dataset, random_split\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "import codecs\r\n",
        "import os\r\n",
        "\r\n",
        "import tensorboard as tb\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "import random\r\n",
        "\r\n",
        "writer = SummaryWriter('runs/word2vec')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZifcs_HULHo",
        "outputId": "d4a69992-23f9-4d88-85a8-f0966bd5cb48"
      },
      "source": [
        "# only run when running with data on mounted drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCmuKUmXD7rK"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "# !unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V38uzVSk9lbi"
      },
      "source": [
        "# Setting random seed and device\r\n",
        "SEED = 1\r\n",
        "\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "# mount drive\r\n",
        "if not os.path.exists('/content/drive/MyDrive/ICL AI/NLP/NLP_cw'):\r\n",
        "    print(\"making dir\")\r\n",
        "    os.makedirs('/content/drive/MyDrive/ICL AI/NLP/NLP_cw')\r\n",
        "\r\n",
        "# root_path = '/content/drive/MyDrive/ICL AI/NLP/NLP_cw/' for running from a mounted google drive\r\n",
        "\r\n",
        "# get runtime type\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FMny8--sCS"
      },
      "source": [
        "## Hyperparameters and data loading\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uONHCtoV-vuZ"
      },
      "source": [
        "# Load data for training purposes\r\n",
        "\r\n",
        "# These lines are for running files stored on a mounted google drive\r\n",
        "# train_df = pd.read_csv(f'{root_path}train.csv')\r\n",
        "# dev_df = pd.read_csv(f'{root_path}dev.csv')\r\n",
        "# test_df = pd.read_csv(f'{root_path}test.csv')\r\n",
        "\r\n",
        "# make sure data is in same folder as this file!\r\n",
        "# can be done with \"upload to session storage\" button in the files tab\r\n",
        "train_df = pd.read_csv('train.csv')\r\n",
        "dev_df = pd.read_csv('dev.csv')\r\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k53yu8r19o6S"
      },
      "source": [
        "# Number of epochs\r\n",
        "epochs = 10\r\n",
        "\r\n",
        "# Proportion of training data for train compared to dev\r\n",
        "train_proportion = 0.8\r\n",
        "\r\n",
        "# which batch size?\r\n",
        "BATCH_SIZE = 32  # hyperparam"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuGH1nhICbS"
      },
      "source": [
        "# which model?\r\n",
        "# this affects:\r\n",
        "# - train/evaluation, as BiLSTM has an extra hidden layer initialisation step\r\n",
        "# - creation of features, as BiLSTM features are padded within batches and FFN\r\n",
        "#   features are padded within the entire dataset\r\n",
        "\r\n",
        "options_models = [\"BiLSTM\", \"BiLSTM-Attention\", \"FFN\"]\r\n",
        "\r\n",
        "model_to_run = 0  # 0 = BiLSTM, 1 = BiLSTM-Attention, 2 = FFN\r\n",
        "\r\n",
        "# which embedding?\r\n",
        "# affects:\r\n",
        "# - which embeddings file is loaded and used to make word2id, idx2word & wvecs\r\n",
        "# - which tokenizer is used, as GloVe doesn't play nice with the ntkl tokenizer\r\n",
        "\r\n",
        "# running with mounted drive\r\n",
        "# options = [f'{root_path}glove.6B.100d.txt', 'custom_word2vec.txt', \"custom_fasttext.txt\"]\r\n",
        "\r\n",
        "# running with files in working dir\r\n",
        "options = ['glove.6B.100d.txt', 'custom_word2vec.txt', \"custom_fasttext.txt\"]\r\n",
        "\r\n",
        "picked_embeddings = 1  # 0 = pre-made glove, 1 = custom word2vec, 2 = custom fasttext\r\n",
        "\r\n",
        "# file to load the embeddings from\r\n",
        "# embedding files should be txt and located in the same working dir as the .ipynb\r\n",
        "file_to_load = options[picked_embeddings]  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eun0sMvJ90GZ"
      },
      "source": [
        "## Preprocessing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypvEawWUBhnu"
      },
      "source": [
        "### Making vocabulary\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLXdY2DBBazo"
      },
      "source": [
        "def create_vocab(data):\r\n",
        "    \"\"\"\r\n",
        "    Creating a corpus of all the tokens used\r\n",
        "    \"\"\"\r\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\r\n",
        "    punctuation_exclusion = [\",\", \"\\'\", \"\\\"\", \".\", \"‘\", \"’\"] \r\n",
        "\r\n",
        "    for sentence in data:\r\n",
        "\r\n",
        "        if picked_embeddings == 0: # glove embeddings\r\n",
        "\r\n",
        "          tokenized_sentence = []\r\n",
        "          for token in sentence.split(' '): # simplest split is whitespace\r\n",
        "            tokenized_sentence.append(token)\r\n",
        "\r\n",
        "            # tokenized_corpus.append(tokenized_sentence)\r\n",
        "        else:\r\n",
        "          # using nltk tokenizer for custom embeddings        \r\n",
        "          tokenized_sentence = nltk.tokenize.word_tokenize(sentence.lower())\r\n",
        "\r\n",
        "        cleaned = [token for token in tokenized_sentence if token not in punctuation_exclusion]\r\n",
        "        tokenized_corpus.append(cleaned)\r\n",
        "\r\n",
        "    # Create single list of all vocabulary\r\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\r\n",
        "\r\n",
        "    for sentence in tokenized_corpus:\r\n",
        "\r\n",
        "        for token in sentence:\r\n",
        "\r\n",
        "            if token not in vocabulary:\r\n",
        "\r\n",
        "                if True:\r\n",
        "                    vocabulary.append(token)\r\n",
        "\r\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grvrWYyxBk3o"
      },
      "source": [
        "### Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfyNRwh3Bd-g"
      },
      "source": [
        "# not changed compared to provided implementation\r\n",
        "def collate_fn_padd(batch):\r\n",
        "    '''\r\n",
        "    We add padding to our minibatches and create tensors for our model\r\n",
        "    '''\r\n",
        "\r\n",
        "    batch_labels = [l for f, l in batch]\r\n",
        "    batch_features = [f for f, l in batch]\r\n",
        "\r\n",
        "    batch_features_len = [len(f) for f, l in batch]\r\n",
        "\r\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\r\n",
        "\r\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\r\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\r\n",
        "\r\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\r\n",
        "\r\n",
        "    return seq_tensor, batch_labels\r\n",
        "\r\n",
        "class Task1Dataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, train_data, labels):\r\n",
        "        self.x_train = train_data\r\n",
        "        self.y_train = labels\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.y_train)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0RrQJm-BuIZ"
      },
      "source": [
        "## Model\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9KyF1nDm8I"
      },
      "source": [
        "### BiLSTM\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPupmNK0DqAy"
      },
      "source": [
        "# from provided implementation\r\n",
        "class BiLSTM(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\r\n",
        "        super(BiLSTM, self).__init__()\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.device = device\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\r\n",
        "\r\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\r\n",
        "        # with dimensionality hidden_dim.\r\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\r\n",
        "\r\n",
        "        # The linear layer that maps from hidden state space to tag space\r\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        # Before we've done anything, we dont have any hidden state.\r\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\r\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\r\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\r\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\r\n",
        "\r\n",
        "    def forward(self, sentence):\r\n",
        "        embedded = self.embedding(sentence)\r\n",
        "        embedded = embedded.permute(1, 0, 2)\r\n",
        "\r\n",
        "        lstm_out, self.hidden = self.lstm(\r\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\r\n",
        "\r\n",
        "        out = self.hidden2label(lstm_out[-1])\r\n",
        "        return out"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxNyjbbyDtIo"
      },
      "source": [
        "### Custom NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsPapUCRFigV"
      },
      "source": [
        "#### BiLSTM Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlMHTIAFmkB"
      },
      "source": [
        "class BiLSTM_ATT(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM_ATT, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        # Attention layers\n",
        "        self.attention_linear = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim * 2, bias = True),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.attention_softmax = nn.Softmax(dim = 0)\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedded = self.embedding(sentence)\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "        \n",
        "        # Attention Layers\n",
        "        att_in = lstm_out\n",
        "        # Linear operation\n",
        "        att_linear = self.attention_linear(att_in[-1])\n",
        "        \n",
        "        # Apply softmax to get weight of h_ti, t being the num of length of embedded, i being our embedding dim\n",
        "        att_softmax = self.attention_softmax(att_linear)\n",
        "\n",
        "        # Extract feature vector\n",
        "        # Here we extract SUM_(j=1)^t w_i * h_i\n",
        "        feature_vector = torch.sum(att_softmax * att_in, dim=0)\n",
        "        # Feature vector now has size batch size * embedding dim\n",
        "\n",
        "        out = self.hidden2label(feature_vector)\n",
        "        return out"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbIwULGWvcYZ"
      },
      "source": [
        "#### Pytorch dense NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRtNSpGeCb3v"
      },
      "source": [
        "Also attempted a GRU, but it didn't work, so stuck with feed-forward NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0pvde-wu5Ui"
      },
      "source": [
        "class FFN(nn.Module):\r\n",
        "    def __init__(self, embedding_dim, vocab_size, batch_size, max_feature):\r\n",
        "        super(FFN, self).__init__()\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(embedding_dim*max_feature, 128),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(128, 64),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(64, 32),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(32, 1),\r\n",
        "            nn.Tanh()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      # input shape: [batch size, sentence length]\r\n",
        "      input_len = x.size()[1]\r\n",
        "\r\n",
        "      # print(\"input size:\", x.size()) \r\n",
        "      # print(\"input: \", x)\r\n",
        "\r\n",
        "      # embedding output shape: [batch size, sentence length, embedding dim]\r\n",
        "      embedded = self.embedding(x).view((self.batch_size, -1))\r\n",
        "\r\n",
        "      out = self.model(embedded)\r\n",
        "      return out"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZggpD3BMZA"
      },
      "source": [
        "## Train & eval\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Av0OzfBOJx"
      },
      "source": [
        "# We define our training loop\r\n",
        "def train(train_iter, dev_iter, model, number_epoch):\r\n",
        "    \"\"\"\r\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    \r\n",
        "    print(\"Training model.\")\r\n",
        "    print(type(model).__name__)\r\n",
        "\r\n",
        "    train_loss = []\r\n",
        "    valid_loss_l = []\r\n",
        "    train_mse = []\r\n",
        "    valid_mse_l = []\r\n",
        "    train_rmse = []\r\n",
        "    valid_rmse_l = []\r\n",
        "\r\n",
        "    for epoch in range(1, number_epoch+1):\r\n",
        "\r\n",
        "        model.train()\r\n",
        "        epoch_loss = 0\r\n",
        "        epoch_sse = 0\r\n",
        "        no_observations = 0  # Observations used for training so far\r\n",
        "\r\n",
        "        for batch in train_iter:\r\n",
        "\r\n",
        "            feature, target = batch\r\n",
        "\r\n",
        "            feature, target = feature.to(device), target.to(device)\r\n",
        "\r\n",
        "            # for RNN:\r\n",
        "            model.batch_size = target.shape[0]\r\n",
        "            no_observations = no_observations + target.shape[0]\r\n",
        "\r\n",
        "            # initalise hidden layers for BiLSTM (& BiLSTM w/ attention) only\r\n",
        "            if model_to_run == 0 or model_to_run == 1:  \r\n",
        "              model.hidden = model.init_hidden()\r\n",
        "\r\n",
        "            predictions = model(feature).squeeze(1)\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            loss = loss_fn(predictions, target)\r\n",
        "\r\n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            epoch_loss += loss.item()*target.shape[0]\r\n",
        "            epoch_sse += sse\r\n",
        "\r\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\r\n",
        "\r\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\r\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\r\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\r\n",
        "\r\n",
        "        train_loss.append(epoch_loss)\r\n",
        "        valid_loss_l.append(valid_loss)\r\n",
        "        train_mse.append(epoch_mse)\r\n",
        "        valid_mse_l.append(valid_mse)\r\n",
        "        train_rmse.append(epoch_mse**.5)\r\n",
        "        valid_rmse_l.append(valid_mse**.5)\r\n",
        "    return train_loss, train_mse, train_rmse, valid_loss_l, valid_mse_l, valid_rmse_l"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vf1n-U_BRgc"
      },
      "source": [
        "\r\n",
        "# We evaluate performance on our dev set\r\n",
        "def eval(data_iter, model):\r\n",
        "    \"\"\"\r\n",
        "    Evaluating model performance on the dev set\r\n",
        "    \"\"\"\r\n",
        "    model.eval()\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_sse = 0\r\n",
        "    pred_all = []\r\n",
        "    trg_all = []\r\n",
        "    no_observations = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for batch in data_iter:\r\n",
        "            feature, target = batch\r\n",
        "\r\n",
        "            feature, target = feature.to(device), target.to(device)\r\n",
        "\r\n",
        "            # for RNN:\r\n",
        "            model.batch_size = target.shape[0]\r\n",
        "            no_observations = no_observations + target.shape[0]\r\n",
        "            # hidden layers for BiLSTM\r\n",
        "            if model_to_run == 0 or model_to_run == 1:\r\n",
        "              model.hidden = model.init_hidden()\r\n",
        "\r\n",
        "            predictions = model(feature).squeeze(1)\r\n",
        "            loss = loss_fn(predictions, target)\r\n",
        "\r\n",
        "            # We get the mse\r\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\r\n",
        "            sse, __ = model_performance(pred, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()*target.shape[0]\r\n",
        "            epoch_sse += sse\r\n",
        "            pred_all.extend(pred)\r\n",
        "            trg_all.extend(trg)\r\n",
        "\r\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t3UqMhwBWAg"
      },
      "source": [
        "# How we print the model performance\r\n",
        "def model_performance(output, target, print_output=False):\r\n",
        "    \"\"\"\r\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    sq_error = (output - target)**2\r\n",
        "\r\n",
        "    sse = np.sum(sq_error)\r\n",
        "    mse = np.mean(sq_error)\r\n",
        "    rmse = np.sqrt(mse)\r\n",
        "\r\n",
        "    if print_output:\r\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\r\n",
        "\r\n",
        "    return sse, mse"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EZEjWv-B_MP"
      },
      "source": [
        "## Configure data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20DTU-htGi5A"
      },
      "source": [
        "#### Edit original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ScGrt6GqQa"
      },
      "source": [
        "# Edit original sentences\n",
        "# replace word in original sentence with edit substitution\n",
        "\n",
        "import re\n",
        "\n",
        "# train\n",
        "original_training_data = train_df['original']\n",
        "train_edit = train_df['edit']\n",
        "train_edited = [re.sub('<(.+)/>', '<' + edit +'/>', data) for data, edit in zip(original_training_data, train_edit)]\n",
        "\n",
        "# dev\n",
        "original_dev_data = dev_df['original']\n",
        "dev_edit = dev_df['edit']\n",
        "dev_edited = [re.sub('<(.+)/>', '<' + edit + '/>', data) for data, edit in zip(original_dev_data, dev_edit)]\n",
        "\n",
        "# test\n",
        "original_test_data = test_df['original']\n",
        "test_edit = test_df['edit']\n",
        "test_edited = [re.sub('<(.+)/>', '<' + edit + '/>', data) for data, edit in zip(original_test_data, test_edit)]\n",
        "\n",
        "\n",
        "train_df['full_edited'] = train_edited\n",
        "dev_df['full_edited'] = dev_edited\n",
        "test_df['full_edited'] = test_edited"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGdNKissCcoo"
      },
      "source": [
        "#### Setting data, creating vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlZ-1aHeCgNA",
        "outputId": "e157680a-21dd-4bfb-81f7-09115ac6ae1b"
      },
      "source": [
        "# We set our training data and dev data\r\n",
        "training_data = train_df['full_edited']\r\n",
        "dev_data = dev_df['full_edited']\r\n",
        "test_data = test_df[\"full_edited\"]\r\n",
        "\r\n",
        "# Creating word vectors from train data\r\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\r\n",
        "\r\n",
        "# Creating word vectors from dev data\r\n",
        "dev_vocab, dev_tokenized_corpus = create_vocab(dev_data)\r\n",
        "\r\n",
        "# vector for test data\r\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\r\n",
        "print(\"Test vocab created.\")\r\n",
        "\r\n",
        "# Creating joint vocab from dev and train:\r\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, dev_data]))\r\n",
        "print(\"Train & development vocab created.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test vocab created.\n",
            "Train & development vocab created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28wxpSBlbPii",
        "outputId": "3590e7e1-445b-4dbe-98d3-cdbdc3987220"
      },
      "source": [
        "print(joint_tokenized_corpus[:10])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['france', 'is', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', '<', 'twins/', '>', 'without', 'trial', 'in', 'iraq'], ['pentagon', 'claims', '2,000', '%', 'increase', 'in', 'russian', 'trolls', 'after', '<', 'bowling/', '>', 'strikes', 'what', 'does', 'that', 'mean', '?'], ['iceland', 'pm', 'calls', 'snap', 'vote', 'as', 'pedophile', 'furor', 'crashes', '<', 'party/', '>'], ['in', 'an', 'apparent', 'first', 'iran', 'and', 'israel', '<', 'slap/', '>', 'each', 'other', 'militarily'], ['trump', 'was', 'told', 'weeks', 'ago', 'that', 'flynn', 'misled', '<', 'school/', '>', 'president'], ['all', '22', '<', 'sounds/', '>', 'trump', 'made', 'in', 'his', 'speech', 'to', 'congress', 'in', 'one', 'chart'], ['new', 'doj', 'alert', 'system', 'will', 'flag', '<', 'laughter/', '>', 'against', 'police'], ['as', 'someone', 'who', 'grew', 'up', 'among', 'fundamentalist', '<', 'morons/', '>', 'in', 'the', 'us', 'i', \"'m\", 'surprised', 'anyone', \"'s\", 'surprised', 'about', 'roy', 'moore'], ['canadians', 'may', 'pay', 'more', 'taxes', 'than', 'americans', 'but', 'here', \"'s\", 'what', 'they', 'get', 'for', 'their', '<', 'loonies/', '>'], ['dutch', 'minister', 'resigns', 'in', 'drug', 'baron', '<', 'blow/', '>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iq40AKwCnNI"
      },
      "source": [
        "## Creating embeddings\r\n",
        "Pre-trained embeddings (GloVE) should be saved in the same folder as the embeddings created here. This is usually the working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOWJPASFVagz"
      },
      "source": [
        "##### word2vec with gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfPh1wKvVdfi"
      },
      "source": [
        "if picked_embeddings == 1:\r\n",
        "  # word2vec\r\n",
        "  model1 = gensim.models.Word2Vec(joint_tokenized_corpus, min_count = 1,  \r\n",
        "                                size = 100, window = 5, sg = 1)\r\n",
        "\r\n",
        "  model1.wv.save_word2vec_format(\"custom_word2vec.txt\")\r\n",
        "else:\r\n",
        "  print(f\"picked {options[picked_embeddings]} embeddings, so not creating custom word2vec embeddings\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8ZKQnJ029v"
      },
      "source": [
        "##### fasttext with gensim\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZOdY01ydve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f74644-33b9-4441-ec04-49a34cb86041"
      },
      "source": [
        "# fasttext\r\n",
        "# fastText — which is essentially an extension of the word2vec model — \r\n",
        "# treats each *word* as composed of character n-grams. \r\n",
        "\r\n",
        "if picked_embeddings == 2: # fasttext\r\n",
        "  model2 = gensim.models.FastText(joint_tokenized_corpus, min_count = 1,\r\n",
        "                                  size=100, window = 5, sg = 1)\r\n",
        "\r\n",
        "  model2.wv.save_word2vec_format(\"custom_fasttext.txt\")\r\n",
        "else:\r\n",
        "  print(f\"picked {options[picked_embeddings]} embeddings, so not creating custom fasttext embeddings\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picked custom_word2vec.txt embeddings, so not creating custom fasttext embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiqHkiHuxTL_"
      },
      "source": [
        "#### Set embeddings from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Y5_3RHtAen"
      },
      "source": [
        "# We create representations for our tokens\r\n",
        "\r\n",
        "# opens embeddings file set in previous cell\r\n",
        "def create_wvecs(embed_file, vocab, tokenized_corpus):\r\n",
        "  \"\"\"\r\n",
        "  Takes in whatever vocab & corpus\r\n",
        "  embed_file should be .txt file containing embeddings\r\n",
        "  \"\"\"\r\n",
        "  wvecs = [] # word vectors\r\n",
        "  word2idx = [] # word2index\r\n",
        "  idx2word = []\r\n",
        "\r\n",
        "  # This is a large file, it will take a while to load in the memory!\r\n",
        "  with codecs.open(embed_file, 'r','utf-8') as f:\r\n",
        "    index = 1\r\n",
        "    for line in f.readlines():\r\n",
        "      # Ignore the first line - first line typically contains vocab, dimensionality\r\n",
        "      if len(line.strip().split()) > 3:\r\n",
        "        word = line.strip().split()[0]\r\n",
        "        if word in vocab:\r\n",
        "            (word, vec) = (word,\r\n",
        "                      list(map(float,line.strip().split()[1:])))\r\n",
        "            wvecs.append(vec)\r\n",
        "            word2idx.append((word, index))\r\n",
        "            idx2word.append((index, word))\r\n",
        "            index += 1\r\n",
        "\r\n",
        "  wvecs = np.array(wvecs)\r\n",
        "  word2idx = dict(word2idx)\r\n",
        "  idx2word = dict(idx2word)\r\n",
        "\r\n",
        "  vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in tokenized_corpus]\r\n",
        "\r\n",
        "  # To avoid any sentences being empty (if no words match to our word embeddings)\r\n",
        "  vectorized_seqs = [x if len(x) > 0 else [0] for x in vectorized_seqs]\r\n",
        "\r\n",
        "  return wvecs, word2idx, idx2word, vectorized_seqs\r\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXcouB6p7bHa"
      },
      "source": [
        "## Creating batches and model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp5U4D9EDErI"
      },
      "source": [
        "#### Splitting dataset & padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhkAqxzTLI0J"
      },
      "source": [
        "wvecs, word2idx, idx2word, vectorized_seqs = create_wvecs(file_to_load, \r\n",
        "                                                          joint_vocab, \r\n",
        "                                                          training_tokenized_corpus)\r\n",
        "\r\n",
        "\r\n",
        "test_wvecs, _, _, vectorized_seqs_test = create_wvecs(file_to_load, \r\n",
        "                                                      test_vocab, \r\n",
        "                                                      test_tokenized_corpus)\r\n",
        "\r\n",
        "# manual padding to longest sentence\r\n",
        "def find_max_list(list_in):\r\n",
        "    list_len = [len(i) for i in list_in]\r\n",
        "    return max(list_len)\r\n",
        "\r\n",
        "\r\n",
        "# padd entire dataset to the longest sentence\r\n",
        "# used for the FFN, not necessary for the LSTM\r\n",
        "def padd_full_data(input_feature, max_len):\r\n",
        "  padd_feature = []\r\n",
        "  for sentence in input_feature:\r\n",
        "    if len(sentence) < max_len:\r\n",
        "\r\n",
        "      diff = max_len - len(sentence)\r\n",
        "      new_list = [0]*diff\r\n",
        "      sentence.extend(new_list)\r\n",
        "\r\n",
        "      assert len(sentence) == max_len\r\n",
        "\r\n",
        "    padd_feature.append(sentence)\r\n",
        "\r\n",
        "  return padd_feature\r\n",
        "\r\n",
        "if model_to_run == 0 or model_to_run == 1:  # BiLSTM or BiLSTM Attention\r\n",
        "  feature = vectorized_seqs\r\n",
        "  max_len = 90348 # placeholder, not used\r\n",
        "elif model_to_run == 2:  # FFN, all batches need to have same length\r\n",
        "\r\n",
        "  # check whether theres a sequence in the test set thats longer than in train\r\n",
        "  max_len_train = find_max_list(vectorized_seqs)\r\n",
        "  max_len_test = find_max_list(vectorized_seqs_test)\r\n",
        "\r\n",
        "  if max_len_train > max_len_test:\r\n",
        "    max_len = max_len_train\r\n",
        "  else:\r\n",
        "    max_len = max_len_test\r\n",
        "\r\n",
        "  # pad training sequences to max length in entire dataset\r\n",
        "  feature = padd_full_data(vectorized_seqs, max_len)\r\n",
        "\r\n",
        "  # pad test sequences to max length in entire dataset\r\n",
        "  feature_test = padd_full_data(vectorized_seqs_test, max_len)\r\n",
        "    "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS1JwXi5C71_"
      },
      "source": [
        "#### Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oARCFR5CDBIm",
        "outputId": "870e0e57-754b-4b54-85ed-28df4e6aa180"
      },
      "source": [
        "INPUT_DIM = len(word2idx)  # numbers of tokens\r\n",
        "EMBEDDING_DIM = 100  # hyperparam\r\n",
        "MAX_LEN = max_len\r\n",
        "\r\n",
        "if model_to_run == 2:  # FFN, max len is length all sentences are padded to\r\n",
        "  model = FFN(EMBEDDING_DIM, INPUT_DIM, BATCH_SIZE, MAX_LEN)\r\n",
        "elif model_to_run == 0: # BiLSTM, 50 is hidden state size\r\n",
        "  model = BiLSTM(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\r\n",
        "elif model_to_run == 1: # BiLSTM Attention, 50 is hidden state size\r\n",
        "  model = BiLSTM_ATT(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\r\n",
        "\r\n",
        "print(\"Model initialised.\")\r\n",
        "\r\n",
        "model.to(device)\r\n",
        "# We provide the model with our embeddings\r\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2626, -0.3225, -0.4336,  ..., -0.0722, -0.0509,  0.0011],\n",
              "        [-0.1892, -0.1796, -0.2195,  ..., -0.2408, -0.1251, -0.2302],\n",
              "        [-0.1900,  0.0996, -0.3005,  ...,  0.0351, -0.1225, -0.2365],\n",
              "        ...,\n",
              "        [-0.0230, -0.0565, -0.0452,  ..., -0.0168, -0.0100, -0.0215],\n",
              "        [-0.0227, -0.0621, -0.0484,  ..., -0.0228, -0.0090, -0.0210],\n",
              "        [-0.0217, -0.0533, -0.0508,  ..., -0.0258, -0.0096, -0.0175]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95pmtD63Yq-e"
      },
      "source": [
        "### Creating train & dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhvywH_XDHfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0429ba-a28c-4450-fe51-6ff8f6787ad5"
      },
      "source": [
        "\r\n",
        "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\r\n",
        "\r\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\r\n",
        "dev_examples = len(train_and_dev) - train_examples\r\n",
        "\r\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\r\n",
        "                                           (train_examples,\r\n",
        "                                            dev_examples))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\r\n",
        "\r\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrL21L4V7dVS"
      },
      "source": [
        "## Running model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM69uHwxDILw"
      },
      "source": [
        "#### Running model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfpiPnn792fZ",
        "outputId": "d69823ce-fd23-4c8e-beea-6fda16654dd0"
      },
      "source": [
        "loss_fn = nn.MSELoss()\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "print(f\"running model {options_models[model_to_run]} with embeddings {file_to_load}\")\r\n",
        "\r\n",
        "# save variables for making graphs\r\n",
        "train_l, train_mse, train_rmse, valid_l, valid_mse, valid_rmse = train(train_loader,dev_loader, model,epochs)\r\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running model BiLSTM with embeddings custom_word2vec.txt\n",
            "Training model.\n",
            "BiLSTM\n",
            "| Epoch: 01 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 03 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
            "| Epoch: 04 | Train Loss: 0.15 | Train MSE: 0.15 | Train RMSE: 0.39 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
            "| Epoch: 05 | Train Loss: 0.10 | Train MSE: 0.10 | Train RMSE: 0.32 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 06 | Train Loss: 0.08 | Train MSE: 0.08 | Train RMSE: 0.28 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 07 | Train Loss: 0.06 | Train MSE: 0.06 | Train RMSE: 0.24 |         Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 08 | Train Loss: 0.05 | Train MSE: 0.05 | Train RMSE: 0.22 |         Val. Loss: 0.42 | Val. MSE: 0.42 |  Val. RMSE: 0.65 |\n",
            "| Epoch: 09 | Train Loss: 0.04 | Train MSE: 0.04 | Train RMSE: 0.20 |         Val. Loss: 0.42 | Val. MSE: 0.42 |  Val. RMSE: 0.65 |\n",
            "| Epoch: 10 | Train Loss: 0.04 | Train MSE: 0.04 | Train RMSE: 0.19 |         Val. Loss: 0.42 | Val. MSE: 0.42 |  Val. RMSE: 0.65 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIwn7Wg3HTlY"
      },
      "source": [
        "#### Running model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5X2w0-zHl_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd42a88c-2195-4bbf-d1d7-70d34838f774"
      },
      "source": [
        "def model_test(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the test set\n",
        "    \"\"\"\n",
        "    test_loss, test_mse, _, _ = eval(data_iter, model)\n",
        "\n",
        "    print(f'| Test Loss: {test_loss:.2f} | Test MSE: {test_mse:.2f} |  Test RMSE: {test_mse**0.5:.2f} |')\n",
        "\n",
        "test_data = test_df['full_edited']\n",
        "\n",
        "# test vocab, test_wvecs & vectorized_seqs_test are already initialised above\n",
        "\n",
        "# We provide the model with our embeddings\n",
        "if model_to_run == 0 or model_to_run == 1:  # BiLSTM or BiLSTM with attention\n",
        "  feature_test = vectorized_seqs_test\n",
        "elif model_to_run == 2: # FFN\n",
        "  feature_test = feature_test  # already set earlier on\n",
        "\n",
        "test_dataset = Task1Dataset(feature_test, test_df['meanGrade'])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, \n",
        "                                          batch_size=BATCH_SIZE, \n",
        "                                          collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "print(f\"Testing on {options_models[model_to_run]} with embeddings {file_to_load}\")\n",
        "model_test(test_loader, model)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n",
            "Testing on BiLSTM with embeddings custom_word2vec.txt\n",
            "| Test Loss: 0.53 | Test MSE: 0.53 |  Test RMSE: 0.73 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxfEKTjbv84T"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3sZskBf7v-_j",
        "outputId": "939c38bd-e54b-4f80-9fc5-f5b2b52f60b3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.style.use(\"bmh\")\r\n",
        "plt.plot(np.arange(0, len(train_l)), train_l, label=\"train loss\")\r\n",
        "plt.plot(np.arange(0, len(valid_l)), valid_l, label=\"validation loss\")\r\n",
        "\r\n",
        "# plt.plot(np.arange(0, len(train_rsme)), train_rsme, label=\"train RMSE\")\r\n",
        "# plt.plot(np.arange(0, len(valid_rsme)), valid_rsme, label=\"validation RMSE\")\r\n",
        "plt.legend(loc=\"best\")\r\n",
        "\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.xlabel(\"epochs\")\r\n",
        "\r\n",
        "plt.title(f\"Train and validation loss over the epochs for {options_models[model_to_run]} model\\n\"\r\n",
        "          f\"Trained on {file_to_load} embeddings\")\r\n",
        "\r\n",
        "plt.show()\r\n",
        "# print(train_losses_D)\r\n",
        "# print(train_losses_G)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}