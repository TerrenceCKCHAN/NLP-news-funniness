{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Part2_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TvyemfDlDmu"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRWFk-kelDoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9d9890-0b9d-46ef-89a6-d2cf1df165d2"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-01 08:38:02--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-03-01 08:38:02--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-03-01 08:38:03--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.17MB/s    in 6m 53s  \n",
            "\n",
            "2021-03-01 08:44:56 (1.99 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX9TqmK7lDoK"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import codecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09jt8VRlDoM"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8--Eo2BFcEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5403509-e8aa-4ef8-d76c-11bb690a59d3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqhlzLl6lDoO"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/data/task-1/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/task-1/dev.csv')\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/data/task-1/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RCmF7xulDoP"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAgZW6K1lDoR"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "\n",
        "            feature, target = batch\n",
        "\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzXeDgHmlDob"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            feature, target = batch\n",
        "\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            model.hidden = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, __ = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_22fHHElDog"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcxmqrKhlDoj"
      },
      "source": [
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzQ0KLXslDoq"
      },
      "source": [
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [len(f) for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "    batch_labels = torch.FloatTensor(batch_labels)\n",
        "\n",
        "    return seq_tensor, batch_labels\n",
        "\n",
        "class Task1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISfPz9ONWjYB"
      },
      "source": [
        "import re\r\n",
        "# obtaining edited headline\r\n",
        "idx = 0\r\n",
        "edited = []\r\n",
        "for item in train_df['original']:\r\n",
        "  text = item.strip()\r\n",
        "  m = re.search(r\"\\<[^()]*\\/>\", text)\r\n",
        "  #print(train_df['original'][idx])\r\n",
        "  #print(m.group(0))\r\n",
        "  text = text.replace(m.group(0), train_df['edit'][idx])\r\n",
        "  edited.append(text)\r\n",
        "  idx +=1\r\n",
        "# print(edited)\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDgRA7zS8QFB"
      },
      "source": [
        "# obtaining editied test headline\r\n",
        "idx = 0\r\n",
        "edited_test = []\r\n",
        "for item in test_set['original']:\r\n",
        "  text = item.strip()\r\n",
        "  # finding words to replace in the brackets\r\n",
        "  m = re.search(r\"\\<[^()]*\\/>\", text)\r\n",
        "  # replacing\r\n",
        "  text = text.replace(m.group(0), test_set['edit'][idx])\r\n",
        "  edited_test.append(text)\r\n",
        "  idx +=1\r\n",
        "# print(edited_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdeFaoc3lDpK"
      },
      "source": [
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gm47T4lDpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345b0044-1382-4659-9072-e717264334dc"
      },
      "source": [
        "# ORIGINAL- LINEAR REGRESSION\n",
        "train_and_dev = edited\n",
        "test = edited_test\n",
        "test_y = test_set['meanGrade']\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)\n",
        "\n",
        "# Test predictions\n",
        "test_c = count_vect.transform(test)\n",
        "test_c = transformer.transform(test_c)\n",
        "predicted = regression_model.predict(test_c)\n",
        "print(\"\\nTest performance:\")\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.01 | RMSE: 0.09 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 17.09 | RMSE: 4.13 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 52.21 | RMSE: 7.23 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HyHwHkUlDpa"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DA3q4o1lDpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8ab5ee-455b-42c7-e434-b3e26fdecad4"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjxjK6tme7IA"
      },
      "source": [
        "#### Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_irQj0h7Dkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f6782c-8243-4807-f01c-00915e1a66cd"
      },
      "source": [
        "# Random Forest Regressor\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "regr = RandomForestRegressor(n_estimators = 200, max_depth=20, random_state=0)\r\n",
        "regression_model = regr.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.28 | RMSE: 0.53 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.33 | RMSE: 0.57 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.32 | RMSE: 0.56 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0huBFm9e_W8"
      },
      "source": [
        "#### Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_-U1wjh7B5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28f840e-8992-4084-ef5a-189f7038bb8b"
      },
      "source": [
        "# SVR\r\n",
        "from sklearn import svm\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "model = svm.SVR(C=1.0, kernel='linear', degree=3, epsilon=0.5, gamma='auto')\r\n",
        "regression_model = model.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.18 | RMSE: 0.42 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.33 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZKCqv1vfDOG"
      },
      "source": [
        "####Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q2UnbMjVOe9",
        "outputId": "c2e552ad-0178-4271-b8b4-1d0755ff24a9"
      },
      "source": [
        "# Naive Bayes- MultinomialNB\r\n",
        "#attempt to use for a regression task\r\n",
        "import numpy as np\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "model = MultinomialNB()\r\n",
        "regression_model = model.fit(train_counts, training_y.astype('int'))\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.59 | RMSE: 0.77 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.82 | RMSE: 0.91 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.85 | RMSE: 0.92 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laSETPePfGCn"
      },
      "source": [
        "####Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHgWCw_HlzF4",
        "outputId": "83789f88-9b47-44dc-9098-61c20ea91bc0"
      },
      "source": [
        "# polynomial regression\r\n",
        "\r\n",
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "degree = 2\r\n",
        "reg = make_pipeline(PolynomialFeatures(degree),LinearRegression())\r\n",
        "regression_model = reg.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.00 | RMSE: 0.02 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.43 | RMSE: 0.65 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.42 | RMSE: 0.65 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ASX528rkvY0"
      },
      "source": [
        "#### Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mHYCObWTcZN",
        "outputId": "4ec08ed9-cd69-4727-bca1-cfc881a7b95a"
      },
      "source": [
        "# Ridge Regression\r\n",
        "\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "degree = 2\r\n",
        "reg = Ridge(alpha=1.0, normalize=True)\r\n",
        "regression_model = reg.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.12 | RMSE: 0.34 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.35 | RMSE: 0.59 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0iJbjTktJY"
      },
      "source": [
        "#### Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cj0imQDTb35",
        "outputId": "0ca5440b-67b8-4c05-be9e-13320b4857d3"
      },
      "source": [
        "# Lasso Regression\r\n",
        "from sklearn import linear_model\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "degree = 2\r\n",
        "reg = linear_model.Lasso(alpha = 0.0001)\r\n",
        "regression_model = reg.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.25 | RMSE: 0.50 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.33 | RMSE: 0.57 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.32 | RMSE: 0.56 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOUZgbDkqH2"
      },
      "source": [
        "#### MLP Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDWoZwtATfxm",
        "outputId": "0237a4ff-a667-4a57-fce5-2dabfc893977"
      },
      "source": [
        "#MLP Regressor\r\n",
        "from sklearn.neural_network import MLPRegressor\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english')\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "degree = 2\r\n",
        "reg = MLPRegressor(early_stopping=True)\r\n",
        "regression_model = reg.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.22 | RMSE: 0.47 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.33 | RMSE: 0.58 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.33 | RMSE: 0.57 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_vpSHcfJfg"
      },
      "source": [
        "####Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMy1FxqyTBBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00db0096-89eb-482d-9648-7ad48fbf0323"
      },
      "source": [
        "# stemming\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from nltk.stem.snowball import EnglishStemmer\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "stemmer = EnglishStemmer()\r\n",
        "analyzer = CountVectorizer().build_analyzer()\r\n",
        "\r\n",
        "# defininf function to allow stemming\r\n",
        "def stemmed_words(doc):\r\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(stop_words='english', analyzer=stemmed_words)\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "regr = RandomForestRegressor(max_depth=20, random_state=0)\r\n",
        "#regression_model = LinearRegression().fit(train_counts, training_y)\r\n",
        "regression_model = regr.fit(train_counts, training_y)\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.27 | RMSE: 0.52 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.33 | RMSE: 0.57 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.32 | RMSE: 0.56 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95cFKKufNW4"
      },
      "source": [
        "#### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIxVquVzEUrT",
        "outputId": "85dca1eb-2f76-4e3d-cca4-c6bbd782df54"
      },
      "source": [
        "# imports to carry out lemmatization\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z86WxRD-oWrI",
        "outputId": "85086b5a-8f40-439f-d9de-32266a702e75"
      },
      "source": [
        "#Lemmatization\r\n",
        "from nltk import word_tokenize          \r\n",
        "from nltk.stem import WordNetLemmatizer \r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "# defining class for lemmatizing\r\n",
        "class LemmaTokenizer(object):\r\n",
        "    def __init__(self):\r\n",
        "        self.wnl = WordNetLemmatizer()\r\n",
        "    def __call__(self, articles):\r\n",
        "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\r\n",
        "\r\n",
        "train_and_dev = edited\r\n",
        "test = edited_test\r\n",
        "test_y = test_set['meanGrade']\r\n",
        "\r\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(edited, train_df['meanGrade'],\r\n",
        "                                                                        test_size=(1-train_proportion),\r\n",
        "                                                                                        random_state=42)\r\n",
        "\r\n",
        "# We train a Tf-idf model\r\n",
        "count_vect = CountVectorizer(tokenizer=LemmaTokenizer(),\r\n",
        "                                # stop_words = 'english', # removed because it wasn't compatible\r\n",
        "                                lowercase = True)\r\n",
        "train_counts = count_vect.fit_transform(training_data)\r\n",
        "transformer = TfidfTransformer().fit(train_counts)\r\n",
        "train_counts = transformer.transform(train_counts)\r\n",
        "regr = RandomForestRegressor(max_depth=20, random_state=0)\r\n",
        "#regression_model = LinearRegression().fit(train_counts, training_y)    # previous experiment\r\n",
        "regression_model = regr.fit(train_counts, training_y)\r\n",
        "\r\n",
        "# Train predictions\r\n",
        "predicted_train = regression_model.predict(train_counts)\r\n",
        "\r\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\r\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\r\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\r\n",
        "\r\n",
        "test_counts = count_vect.transform(dev_data)\r\n",
        "\r\n",
        "test_counts = transformer.transform(test_counts)\r\n",
        "\r\n",
        "# Dev predictions\r\n",
        "predicted = regression_model.predict(test_counts)\r\n",
        "\r\n",
        "# We run the evaluation:\r\n",
        "print(\"\\nTrain performance:\")\r\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\r\n",
        "\r\n",
        "print(\"\\nDev performance:\")\r\n",
        "sse, mse = model_performance(predicted, dev_y, True)\r\n",
        "# Test predictions\r\n",
        "test_c = count_vect.transform(test)\r\n",
        "test_c = transformer.transform(test_c)\r\n",
        "predicted = regression_model.predict(test_c)\r\n",
        "print(\"\\nTest performance:\")\r\n",
        "sse, mse = model_performance(predicted, test_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.27 | RMSE: 0.52 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.33 | RMSE: 0.57 |\n",
            "\n",
            "Test performance:\n",
            "| MSE: 0.32 | RMSE: 0.56 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJrelW7DrJw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}