# NLP-news-funniness


## Part 1 Implementation
To access part 1 implementation, please refer to the file Part1_combined.ipynb
Collab Link:

The file comes with three models and three different embeddings to choose from and shows the train, validation and test loss as well as graphs showing the losses vs epochs during training.

To run different models, please change the 
model_to_run parameter, with 0 = BiLSTM, 1 = BiLSTM-Attention, 2 = FFN

To run different embeddings, please change the parameter
picked_embeddings, with 0 = pre-made glove, 1 = custom word2vec, 2 = custom fasttext

## Part 2 Implementation


